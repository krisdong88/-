{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Normalization和Batch Normalization的区别："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一句话版本：\n",
    "\n",
    "Batch Normalization 依赖于整个批次的数据来进行归一化，适合CNN 如（AlexNet https://zhuanlan.zhihu.com/p/133712585，VGG https://zhuanlan.zhihu.com/p/42233779，ResNet https://zhuanlan.zhihu.com/p/56961832），而 Layer Normalization 依赖于单个数据点的所有特征，适合RNN（https://zhuanlan.zhihu.com/p/30844905）和Transformer(https://zhuanlan.zhihu.com/p/338817680)模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "详细版本：\n",
    "\n",
    "Batch Normalization（批量归一化）和 Layer Normalization（层归一化）都是深度学习中常用的归一化技术，用于加速模型训练和改善模型的泛化能力。虽然这两种技术的目标相同，即通过调整神经网络中间层的输出来稳定学习过程，但它们在归一化的维度和应用场景上有所不同。\n",
    "\n",
    "Batch Normalization（批量归一化）\n",
    "Batch Normalization（BN）是在每个训练批次的基础上对每个特征单独进行归一化。具体而言，BN 对每个特征（在卷积网络中是每个通道）计算批次中所有样本的均值和标准差，并用这些统计数据来归一化相应的特征。\n",
    "\n",
    "优点：\n",
    "\n",
    "加速收敛：通过减少内部协变量偏移（Internal Covariate Shift），BN 可以让模型使用更高的学习率，从而加速收敛。\n",
    "提供一定的正则化效果：由于批量归一化的随机性（每个批次的样本不同），它能提供轻微的正则化效果。\n",
    "缺点：\n",
    "\n",
    "依赖批次大小：BN 的效果依赖于较大的批次大小，因为每个批次内需要足够的样本来计算可靠的均值和标准差。\n",
    "性能下降问题：在小批量数据上可能会导致估计的均值和标准差不准确，影响模型表现。\n",
    "Layer Normalization（层归一化）\n",
    "Layer Normalization 则是对单个样本的所有特征进行归一化，通常应用于递归神经网络（RNN）和 Transformer 类模型。与 BN 不同，LN 不依赖于批次的大小，它在单个样本的所有激活上计算均值和标准差。\n",
    "\n",
    "优点：\n",
    "\n",
    "不依赖批次大小：LN 的计算只依赖于单个样本，因此适用于批次大小较小或者动态变化的批次大小的情况。\n",
    "适用于RNN和Transformer：由于其计算方式，LN 在处理时间序列数据和处理长距离依赖的模型中表现更好。\n",
    "缺点：\n",
    "\n",
    "可能不如BN有效：在某些情况下，特别是在卷积神经网络（CNN）中，LN 可能不如 BN 有效，因为它不利用批次中样本之间的统计信息。\n",
    "应用选择\n",
    "Batch Normalization 更适用于卷积神经网络和较大批次的场景。\n",
    "Layer Normalization 更适用于处理时间序列数据的模型，如 RNN 和 Transformer，以及批次大小不一或非常小的场景。\n",
    "归一化技术的选择取决于具体的应用场景和模型架构。理解它们的工作原理和适用性可以帮助你更好地设计和优化深度学习模型。如果你有更多关于这些技术的问题或者需要进一步的解释，请随时提出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN要怎么计算维度？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一句话版本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "详细版本:\n",
    "假设你有一个输入层的尺寸为 32(H)×32(H)，使用5（F)×5(F) 的滤波器，S(步长)为 1，没有填充（P=0）。 输出层的维度就是28，因为 Floor((H + 2P - F)/S + 1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
