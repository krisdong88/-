{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用启发式的搜索算法来找，用selective search来选择锚框，选出很多锚框然后当作一张图片，然后用训练好的模型像VGG或者Alexnet来抽特征，然后用SVM来进行分类，再用一个线性回归模型来预测偏移。 使用ROI Pooling来做batch，给定一个锚框，然后均匀切成N*M块，然后输出每一块里面的最大值，好处就是不管锚框是什么形状，都可以生产nm个值，然后就可以做batch了，处理起来就方便了，这就是RCNN里面很关键的一个层就是ROI POOLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要的改进，就是一张图片都要抽锚框，但是如果一个图片有1000个锚框，那不就要1000个锚框做CNN来抽特征，那计算量太大了相当于1000张图片了，fast rcnn就是对整个图片来抽特征，那不就有7 * 7 或者什么的特征图嘛，然后再去做selective search，这样不就出锚框了么，那再映射到原图上面去，就直接按比例给映射到原图上面去，然后再用ROI pooling对每个锚框抽特征，相当于如果有100个锚框那就会变成100 * 4的向量，然后进全连接层，然后再对每一个锚框做预测，还有和真实的bounding box的偏移。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就觉得Fast R-CNN还不够快，所以要在快一点 ，用一个神经网络来替代之前的选择性搜索的算法，RPN region propose network，CNN进去，把CNN的输出，ROI pooling需要CNN的特征和锚框，做卷积层，然后找到锚框，然后做一个二分类，来确定这个锚框到底是不是一个好的锚框，然后看看他的偏移，找完以后，通过NMS，就是把重叠之类的锚框给你删除，然后到ROI，所以RPN就是小一点槽一点的目标检测网络。两次预测两个stage。实际上还是很慢的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和Fast R-CNN是一样的，他加了一个东西，就假如你有像素的label，比如COCO数据集，有这个信息的话，在ROI出来之后到FCN，然后出来一个Mask的prediction通过标号来提升性能，ROI Pooling变成了ROI Align，像素很多的话会导致像素级的偏移，所以会导致边缘不准确，假设是3*3 ROI就是2*2 而 align就是直接在中间切开了，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "faster-RCNN 跑的慢但是精度高，但是像YOLO这种就是速度快但是精度没有这么高也就是mAP\n",
    "如果你对精度非常重视肯定是fast rcnn重要，但是工业界肯定是速度为王。\n",
    "总结一下就是 R-CNN是最早，也是最有名的一类基于锚框和CNN的目标检测算法，然后Fast和Faster R-CNN就是提升R-CNN的性能，然后Faster R-CNN和Mask R-CNN是在追求高精度场景下的常用算法。\n",
    "无人车方面的话肯定Mask R-CNN是很好的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSD Single Shot Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "会对每个像素为中心生成多个以它为中心的锚框。\n",
    "给定这么多锚框就直接对这些锚框做预测，一个图片过来，先抽特征用CNN，然后对每个特征\n",
    "SSD 通过单神经网络来检测模型\n",
    "以每个像素为中心的产生多个锚框\n",
    "在多个段的输出上进行多尺度的检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSD中锚框有大量重叠的问题，所以浪费了很多的计算， 然后YOLO将图片均匀分成S*S个锚框，然后每个锚框再预测B个边缘框，并且还在一直持续的改进预测的数量就是S^2 * B。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO V3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO V3 和 YOLO的区别就在于原始YOLO使用单一尺度的网格来预测bounding box， 但是V3 会使用三个不同尺度的特征图来进行预测，这样可以更好的检测不同大小的对象，然后在bounding box的预测方面，原始的YOLO会在每个单元格预测两个Bounding box会包含五个值，x,y,w,h,还有confidence，但是v3会预测三个bounding box，并且会引入锚点anchors来预设bounding box的形状，然后帮助模型预测更加精确的框。在类别预测方面，原始的使用cofidence这个概念，把类别的confidence和对象的置信度相乘来获得置信度，但是在V3里面使用了logistic regression来预测每个类别的分数不使用softmax并且每个类都有独立的逻辑分类器。在架构方面，原始使用了24个卷积层，和两个全连接，YOLOv3使用了Darknet 53 使用了很多的resnet架构，提升稳定性和加速收敛速度，精准度和性能V3都要比原始的要好然后v3在训练过程中使用了多尺度训练，可以自适应图像尺寸，有助于模型在不同尺寸的图片上都能维持性能。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
